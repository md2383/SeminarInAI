{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30887,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/md2383/SeminarInAI/blob/main/Week06_bert/homework_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Homework 5 (10pt): Question search engine\n",
        "\n",
        "Remeber Week01, where you used GloVe embeddings to find related questions? That was... cute. Now, it's time to really solve this task using context-aware embeddings.\n",
        "\n",
        "__Warning:__ this task assumes you have seen `practice06.ipynb` [notebook](https://github.com/anton-selitskiy/RIT_LLM/blob/main/Week06_bert/practice06.ipynb)\n",
        "\n",
        "This assignmend is inspired by this [notebook](https://github.com/yandexdataschool/nlp_course/blob/2024/week05_transfer/homework.ipynb)"
      ],
      "metadata": {
        "id": "Wlu-s2k9D1Ba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%pip install --upgrade transformers datasets accelerate deepspeed\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import transformers\n",
        "import datasets"
      ],
      "metadata": {
        "id": "HYffoHiI8du5",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T23:32:24.677259Z",
          "iopub.execute_input": "2025-02-18T23:32:24.677572Z",
          "iopub.status.idle": "2025-02-18T23:32:32.330860Z",
          "shell.execute_reply.started": "2025-02-18T23:32:24.677544Z",
          "shell.execute_reply": "2025-02-18T23:32:32.330184Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load data and model"
      ],
      "metadata": {
        "id": "HfSHyQlT-fVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qqp = datasets.load_dataset('SetFit/qqp')\n",
        "print('\\n')\n",
        "print(\"Sample[0]:\", qqp['train'][0])\n",
        "print(\"Sample[3]:\", qqp['train'][3])"
      ],
      "metadata": {
        "id": "Y2_wgtrx8e6C",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T23:32:32.331770Z",
          "iopub.execute_input": "2025-02-18T23:32:32.332114Z",
          "iopub.status.idle": "2025-02-18T23:32:37.538516Z",
          "shell.execute_reply.started": "2025-02-18T23:32:32.332094Z",
          "shell.execute_reply": "2025-02-18T23:32:37.537884Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gchhablani/bert-base-cased-finetuned-qqp\"\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "pStlWcvD8rdk",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T19:38:21.326118Z",
          "iopub.execute_input": "2025-02-18T19:38:21.326646Z",
          "iopub.status.idle": "2025-02-18T19:38:41.323030Z",
          "shell.execute_reply.started": "2025-02-18T19:38:21.326615Z",
          "shell.execute_reply": "2025-02-18T19:38:41.321612Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenize the data"
      ],
      "metadata": {
        "id": "hM3ZujeZ-Z7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 128\n",
        "def preprocess_function(examples):\n",
        "    result = tokenizer(\n",
        "        examples['text1'], examples['text2'],\n",
        "        padding='max_length', max_length=MAX_LENGTH, truncation=True\n",
        "    )\n",
        "    result['label'] = examples['label']\n",
        "    return result\n",
        "\n",
        "qqp_preprocessed = qqp.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "id": "qtkllSPG9bTL",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T19:38:49.441562Z",
          "iopub.execute_input": "2025-02-18T19:38:49.442588Z",
          "iopub.status.idle": "2025-02-18T19:40:24.278815Z",
          "shell.execute_reply.started": "2025-02-18T19:38:49.442558Z",
          "shell.execute_reply": "2025-02-18T19:40:24.278038Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(repr(qqp_preprocessed['train'][0]['input_ids'])[:100], \"...\")"
      ],
      "metadata": {
        "id": "ObMcFN59_Ll2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T19:40:24.279984Z",
          "iopub.execute_input": "2025-02-18T19:40:24.280305Z",
          "iopub.status.idle": "2025-02-18T19:40:24.287423Z",
          "shell.execute_reply.started": "2025-02-18T19:40:24.280270Z",
          "shell.execute_reply": "2025-02-18T19:40:24.286529Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(qqp_preprocessed['train'][0]['input_ids']))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T19:40:24.288839Z",
          "iopub.execute_input": "2025-02-18T19:40:24.289075Z",
          "iopub.status.idle": "2025-02-18T19:40:24.658139Z",
          "shell.execute_reply.started": "2025-02-18T19:40:24.289054Z",
          "shell.execute_reply": "2025-02-18T19:40:24.657150Z"
        },
        "id": "OV0i_trzGxLA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1: evaluation (3 point)\n",
        "\n",
        "We randomly chose a model trained on QQP - but is it any good?\n",
        "\n",
        "One way to assess this is by measuring validation accuracy, which you will implement next.\n",
        "\n",
        "Hereâ€™s the interface to help you get started:"
      ],
      "metadata": {
        "id": "PyQ1ZbzGAUF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_set = qqp_preprocessed['validation']\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_set, batch_size=1, shuffle=False, collate_fn=transformers.default_data_collator, num_workers=2\n",
        ")"
      ],
      "metadata": {
        "id": "M5ueSoieAbBg",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T23:32:13.981271Z",
          "iopub.execute_input": "2025-02-18T23:32:13.981563Z",
          "iopub.status.idle": "2025-02-18T23:32:13.990865Z",
          "shell.execute_reply.started": "2025-02-18T23:32:13.981538Z",
          "shell.execute_reply": "2025-02-18T23:32:13.989774Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in val_loader:\n",
        "    break  # here will be your training code later. For now, it reads one batch\n",
        "print(\"Sample batch:\", batch)\n",
        "\n",
        "with torch.no_grad():\n",
        "  predicted = model(\n",
        "      input_ids=batch['input_ids'],\n",
        "      attention_mask=batch['attention_mask'],\n",
        "      token_type_ids=batch['token_type_ids']\n",
        "  )\n",
        "\n",
        "print('\\nPrediction (probs):', torch.softmax(predicted.logits, dim=1).data.numpy())"
      ],
      "metadata": {
        "id": "SsPwXXx-At-i",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T19:40:36.760446Z",
          "iopub.execute_input": "2025-02-18T19:40:36.760770Z",
          "iopub.status.idle": "2025-02-18T19:40:51.373736Z",
          "shell.execute_reply.started": "2025-02-18T19:40:36.760747Z",
          "shell.execute_reply": "2025-02-18T19:40:51.372727Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Your task__ is to measure the validation accuracy of your model.\n",
        "Doing so naively may take several hours. Please make sure you use the following optimizations:\n",
        "\n",
        "- run the model on GPU with no_grad\n",
        "- using batch size larger than 1\n",
        "- use optimize data loader with num_workers > 1\n",
        "- (optional) use [mixed precision](https://pytorch.org/docs/stable/notes/amp_examples.html)\n"
      ],
      "metadata": {
        "id": "RoxHzxn0DQqO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T19:41:19.390240Z",
          "iopub.execute_input": "2025-02-18T19:41:19.390609Z",
          "iopub.status.idle": "2025-02-18T19:41:19.394631Z",
          "shell.execute_reply.started": "2025-02-18T19:41:19.390571Z",
          "shell.execute_reply": "2025-02-18T19:41:19.393619Z"
        },
        "id": "CV4EfZpJGxLA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T19:41:19.662889Z",
          "iopub.execute_input": "2025-02-18T19:41:19.663179Z",
          "iopub.status.idle": "2025-02-18T19:41:20.062483Z",
          "shell.execute_reply.started": "2025-02-18T19:41:19.663156Z",
          "shell.execute_reply": "2025-02-18T19:41:20.061582Z"
        },
        "id": "rVisozXgGxLA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T23:33:03.019153Z",
          "iopub.execute_input": "2025-02-18T23:33:03.019619Z",
          "iopub.status.idle": "2025-02-18T23:33:03.023118Z",
          "shell.execute_reply.started": "2025-02-18T23:33:03.019595Z",
          "shell.execute_reply": "2025-02-18T23:33:03.022433Z"
        },
        "id": "3dodymkdGxLA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# <A lot of YOUR CODE HERE>\n",
        "# ...\n",
        "\n",
        "\n",
        "accuracy = #<Validation accuracy, between 0 and 1>\n"
      ],
      "metadata": {
        "id": "9k5EK7-KA5F2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T05:16:03.757052Z",
          "iopub.execute_input": "2025-02-18T05:16:03.757300Z",
          "iopub.status.idle": "2025-02-18T05:16:03.762556Z",
          "shell.execute_reply.started": "2025-02-18T05:16:03.757278Z",
          "shell.execute_reply": "2025-02-18T05:16:03.761476Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "assert 0.9 < accuracy < 0.91"
      ],
      "metadata": {
        "id": "0R2z_-FZU3qy",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T05:16:16.517878Z",
          "iopub.execute_input": "2025-02-18T05:16:16.518197Z",
          "iopub.status.idle": "2025-02-18T05:16:16.522121Z",
          "shell.execute_reply.started": "2025-02-18T05:16:16.518175Z",
          "shell.execute_reply": "2025-02-18T05:16:16.521334Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2: train the model (5 points)\n",
        "\n",
        "Fine-tune your own model. You are free to choose any model __except for the original BERT.__ We recommend [DeBERTa-v3](https://huggingface.co/microsoft/deberta-v3-base), but you can choose the best model based on public benchmarks (e.g. [GLUE](https://gluebenchmark.com/)).\n",
        "\n",
        "You can write the training code manually (as we did in class) or use transformers.Trainer (see [this example](https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification)). Please make sure that your model's accuracy is at least __comparable__ with the above example for BERT."
      ],
      "metadata": {
        "id": "KONQ1E0J-y6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_name = \"microsoft/deberta-v3-base\"\n",
        "# tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "# model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T23:33:09.217189Z",
          "iopub.execute_input": "2025-02-18T23:33:09.217494Z",
          "iopub.status.idle": "2025-02-18T23:33:38.259309Z",
          "shell.execute_reply.started": "2025-02-18T23:33:09.217466Z",
          "shell.execute_reply": "2025-02-18T23:33:38.258204Z"
        },
        "id": "Sls1fB9DGxLB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "<A whole lot of your code goes here>"
      ],
      "metadata": {
        "id": "T0ZkZTkl_yMU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "GhVwWPwSGxLC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3: try the full pipeline (2 point)\n",
        "\n",
        "Finally, it is time to use your model to find duplicate questions.\n",
        "Please implement a function that takes a question and finds top-5 potential duplicates in the training set. For now, it is fine if your function is slow, as long as it yields correct results.\n",
        "\n",
        "Showcase how your function works with at least 3 examples."
      ],
      "metadata": {
        "id": "wQD0IV44LrSs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zLSjmsKaUyQb"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}